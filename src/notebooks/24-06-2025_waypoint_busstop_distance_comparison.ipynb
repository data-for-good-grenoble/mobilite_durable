{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# üöå Projet MDM - Mobilit√© Durable en Montagne ‚õ∞Ô∏è\n",
    "\n",
    "*Author : Laurent*\n",
    "\n",
    "*Date : 24/06/2025*\n",
    "\n",
    "**Description :**\n",
    "\n",
    "This Jupyter Notebook compares distances between waypoints and bus stops using different methods:\n",
    "1. Pre-calculated distances from the C2C SQL dump\n",
    "2. Distances calculated using routingpy with OpenRouteService API (by foot and by car)\n",
    "\n",
    "It uses pandas/geopandas to parse waypoints from the C2C CSV export for Is√®re `Liste_iti_D4G_isere.csv` \n",
    "and extract bus stop locations from a PostgreSQL SQL C2C dump `dump-c2corg-202505050900.sql`.\n"
   ],
   "id": "cb8d5365f429217"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import binascii\n",
    "import re\n",
    "import struct\n",
    "from time import sleep\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Set display options\n",
    "pd.set_option(\"display.max_columns\", None)"
   ],
   "id": "41a318226778875e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Load and Parse Bus Stop Data from SQL Dump\n",
   "id": "7e330a1434755dc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def parse_sql_dump_stopareas(sql_file):\n",
    "    \"\"\"\n",
    "    Parse the SQL dump to extract bus stops (stopareas) with their coordinates.\n",
    "\n",
    "    Args:\n",
    "        sql_file: Path to the SQL dump file\n",
    "\n",
    "    Returns:\n",
    "        GeoDataFrame with bus stop information\n",
    "    \"\"\"\n",
    "    # Pattern to match INSERT statements for stopareas\n",
    "    insert_pattern = re.compile(r\"INSERT INTO guidebook\\.stopareas VALUES (.*?);\", re.DOTALL)\n",
    "\n",
    "    # List to store parsed stop areas\n",
    "    stopareas = []\n",
    "\n",
    "    with open(sql_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # Process each INSERT statement\n",
    "    for match in insert_pattern.finditer(content):\n",
    "        values_str = match.group(1)\n",
    "\n",
    "        # Split values preserving quoted strings (handling escaped quotes)\n",
    "        values = []\n",
    "        current = \"\"\n",
    "        in_quote = False\n",
    "        escape_next = False\n",
    "\n",
    "        for char in values_str:\n",
    "            if escape_next:\n",
    "                current += char\n",
    "                escape_next = False\n",
    "                continue\n",
    "\n",
    "            if char == \"\\\\\":\n",
    "                escape_next = True\n",
    "                continue\n",
    "\n",
    "            if char == \"'\":\n",
    "                in_quote = not in_quote\n",
    "                continue\n",
    "\n",
    "            if char == \",\" and not in_quote:\n",
    "                values.append(current.strip())\n",
    "                current = \"\"\n",
    "                continue\n",
    "\n",
    "            current += char\n",
    "\n",
    "        if current.strip():\n",
    "            values.append(current.strip())\n",
    "\n",
    "        # Ensure we have enough values (at least 6)\n",
    "        if len(values) < 6:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Extract basic fields\n",
    "            stoparea_id = int(values[0].strip(\"(\"))\n",
    "            navitia_id = values[1].strip(\"'\")\n",
    "            stoparea_name = values[2].strip(\"'\")\n",
    "            line = values[3].strip(\"'\")\n",
    "            operator = values[4].strip(\"'\")\n",
    "            ewkb_hex = values[5].strip(\"')\")\n",
    "\n",
    "            # Skip if geometry is NULL\n",
    "            if ewkb_hex.upper() == \"NULL\":\n",
    "                continue\n",
    "\n",
    "            # Convert hex to binary\n",
    "            try:\n",
    "                ewkb_bytes = binascii.unhexlify(ewkb_hex)\n",
    "            except binascii.Error:\n",
    "                continue\n",
    "\n",
    "            # Check if we have enough data\n",
    "            if len(ewkb_bytes) < 17:  # Minimum for point without SRID\n",
    "                continue\n",
    "\n",
    "            # Read byte order (1 = little, 0 = big)\n",
    "            byte_order = ewkb_bytes[0]\n",
    "            is_little_endian = byte_order == 1\n",
    "\n",
    "            # Read geometry type (4 bytes)\n",
    "            geom_type_bytes = ewkb_bytes[1:5]\n",
    "\n",
    "            # Extract geometry type (first 4 bits) and flags\n",
    "            if is_little_endian:\n",
    "                geom_type = struct.unpack(\"<I\", geom_type_bytes)[0]\n",
    "            else:\n",
    "                geom_type = struct.unpack(\">I\", geom_type_bytes)[0]\n",
    "\n",
    "            # Check if this is a point (type = 1) - ignore flags\n",
    "            if (geom_type & 0x07) != 1:  # Use bitmask to ignore SRID flag and others\n",
    "                continue\n",
    "\n",
    "            # Read SRID if present (bit 3 of geom_type is set)\n",
    "            offset = 5\n",
    "            srid = None\n",
    "            if geom_type & 0x20000000:  # Check if SRID flag is set\n",
    "                if len(ewkb_bytes) < 9:\n",
    "                    continue\n",
    "                if is_little_endian:\n",
    "                    srid = struct.unpack(\"<I\", ewkb_bytes[5:9])[0]\n",
    "                else:\n",
    "                    srid = struct.unpack(\">I\", ewkb_bytes[5:9])[0]\n",
    "                offset = 9\n",
    "\n",
    "            # Read coordinates\n",
    "            if len(ewkb_bytes) < offset + 16:  # 8 bytes for x, 8 for y\n",
    "                continue\n",
    "\n",
    "            # Extract X and Y coordinates\n",
    "            if is_little_endian:\n",
    "                x = struct.unpack(\"<d\", ewkb_bytes[offset : offset + 8])[0]\n",
    "                y = struct.unpack(\"<d\", ewkb_bytes[offset + 8 : offset + 16])[0]\n",
    "            else:\n",
    "                x = struct.unpack(\">d\", ewkb_bytes[offset : offset + 8])[0]\n",
    "                y = struct.unpack(\">d\", ewkb_bytes[offset + 8 : offset + 16])[0]\n",
    "\n",
    "            # Add to list\n",
    "            stopareas.append(\n",
    "                {\n",
    "                    \"stoparea_id\": stoparea_id,\n",
    "                    \"navitia_id\": navitia_id,\n",
    "                    \"stoparea_name\": stoparea_name,\n",
    "                    \"line\": line,\n",
    "                    \"operator\": operator,\n",
    "                    \"srid\": srid,\n",
    "                    \"geometry\": Point(x, y),\n",
    "                }\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            # Skip problematic rows\n",
    "            print(f\"Error parsing row: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Create GeoDataFrame\n",
    "    if stopareas:\n",
    "        gdf = gpd.GeoDataFrame(stopareas, geometry=\"geometry\", crs=\"EPSG:3857\")\n",
    "        return gdf\n",
    "    else:\n",
    "        return gpd.GeoDataFrame([])\n",
    "\n",
    "def parse_sql_dump_waypoints_stopareas(sql_file):\n",
    "    \"\"\"\n",
    "    Parse the SQL dump to extract waypoints_stopareas with their distances.\n",
    "\n",
    "    Args:\n",
    "        sql_file: Path to the SQL dump file\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with waypoint-stoparea distances\n",
    "    \"\"\"\n",
    "    # Pattern to match INSERT statements for waypoints_stopareas\n",
    "    insert_pattern = re.compile(r\"INSERT INTO guidebook\\.waypoints_stopareas VALUES (.*?);\", re.DOTALL)\n",
    "\n",
    "    # List to store parsed waypoints_stopareas\n",
    "    waypoints_stopareas = []\n",
    "\n",
    "    with open(sql_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # Process each INSERT statement\n",
    "    for match in insert_pattern.finditer(content):\n",
    "        values_str = match.group(1)\n",
    "\n",
    "        # Split values preserving quoted strings (handling escaped quotes)\n",
    "        values = []\n",
    "        current = \"\"\n",
    "        in_quote = False\n",
    "        escape_next = False\n",
    "\n",
    "        for char in values_str:\n",
    "            if escape_next:\n",
    "                current += char\n",
    "                escape_next = False\n",
    "                continue\n",
    "\n",
    "            if char == \"\\\\\":\n",
    "                escape_next = True\n",
    "                continue\n",
    "\n",
    "            if char == \"'\":\n",
    "                in_quote = not in_quote\n",
    "                continue\n",
    "\n",
    "            if char == \",\" and not in_quote:\n",
    "                values.append(current.strip())\n",
    "                current = \"\"\n",
    "                continue\n",
    "\n",
    "            current += char\n",
    "\n",
    "        if current.strip():\n",
    "            values.append(current.strip())\n",
    "\n",
    "        # Ensure we have enough values (at least 4)\n",
    "        if len(values) < 4:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Extract fields\n",
    "            stoparea_id = int(values[0].strip(\"(\"))\n",
    "            document_id = int(values[1])\n",
    "            waypoint_id = int(values[2])\n",
    "            distance = float(values[3].strip(\")\"))\n",
    "\n",
    "            # Add to list\n",
    "            waypoints_stopareas.append(\n",
    "                {\n",
    "                    \"waypoint_id\": waypoint_id,\n",
    "                    \"document_id\": document_id,\n",
    "                    \"stoparea_id\": stoparea_id,\n",
    "                    \"distance\": distance,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            # Skip problematic rows\n",
    "            print(f\"Error parsing waypoints_stopareas row: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Create DataFrame\n",
    "    if waypoints_stopareas:\n",
    "        df = pd.DataFrame(waypoints_stopareas)\n",
    "        return df\n",
    "    else:\n",
    "        return pd.DataFrame([])\n",
    "\n",
    "# Load bus stops and waypoints_stopareas from SQL dump\n",
    "sql_file_path = \"../data/C2C/dump-c2corg-202505050900.sql\"\n",
    "\n",
    "try:\n",
    "    # Extract bus stops\n",
    "    stops_gdf = parse_sql_dump_stopareas(sql_file_path)\n",
    "    print(f\"Loaded {len(stops_gdf)} bus stops from SQL dump\")\n",
    "\n",
    "    if not stops_gdf.empty:\n",
    "        print(\"First 2 bus stops:\")\n",
    "        print(stops_gdf.head(2).T)\n",
    "\n",
    "    # Extract waypoints_stopareas\n",
    "    waypoints_stopareas_df = parse_sql_dump_waypoints_stopareas(sql_file_path)\n",
    "    print(f\"Loaded {len(waypoints_stopareas_df)} waypoint-stoparea distances from SQL dump\")\n",
    "\n",
    "    if not waypoints_stopareas_df.empty:\n",
    "        print(\"First 2 waypoint-stoparea distances:\")\n",
    "        print(waypoints_stopareas_df.head(5).T)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: SQL file '{sql_file_path}' not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n"
   ],
   "id": "40f1e70a207bbe5f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Load and Parse Waypoint Data from CSV\n",
   "id": "be127c1801c3b5c6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Read CSV file\n",
    "csv_path = \"../data/C2C/Liste_iti_D4G_isere.csv\"\n",
    "df = pd.read_csv(csv_path, on_bad_lines=\"skip\", low_memory=False)\n",
    "\n",
    "# Display sample data\n",
    "print(\"First 2 rows of original CSV:\")\n",
    "print(df.head(2).T)\n",
    "\n",
    "# Simplified pattern that focuses only on [X, Y] coordinates\n",
    "coord_pattern = re.compile(r\"\\s*([+-]?\\d+[\\.\\d]*)\\s*,\\s*([+-]?\\d+[\\.\\d]*)\\s*\")\n",
    "\n",
    "# List to store parsed waypoints\n",
    "waypoints = []\n",
    "\n",
    "# Identify waypoint columns (columns 9 onward)\n",
    "waypoint_cols = df.columns[9:]\n",
    "\n",
    "# Parse waypoints\n",
    "for idx, row in df.iterrows():\n",
    "    itinerary_id = row[\"Id itin√©raire\"]\n",
    "\n",
    "    for col in waypoint_cols:\n",
    "        cell = str(row[col])\n",
    "        if not cell or cell == \"nan\":\n",
    "            continue\n",
    "\n",
    "        # Extract waypoint ID from cell content instead of column name\n",
    "        waypoint_id = None\n",
    "        # Look for pattern like \"(12345 - Title - [X, Y])\"\n",
    "        # Using search instead of match to find the pattern anywhere in the cell\n",
    "        id_match = re.search(r\"\\(\\s*(\\d+)\\s*-\", cell)\n",
    "        if id_match:\n",
    "            try:\n",
    "                waypoint_id = int(id_match.group(1))\n",
    "            except (ValueError, IndexError):\n",
    "                pass\n",
    "\n",
    "        match = coord_pattern.search(cell)\n",
    "        if match:\n",
    "            try:\n",
    "                x = float(match.group(1))\n",
    "                y = float(match.group(2))\n",
    "\n",
    "                waypoint_data = {\n",
    "                    \"itinerary_id\": itinerary_id,\n",
    "                    \"geometry\": Point(x, y)\n",
    "                }\n",
    "\n",
    "                if waypoint_id:\n",
    "                    waypoint_data[\"waypoint_id\"] = waypoint_id\n",
    "\n",
    "                waypoints.append(waypoint_data)\n",
    "\n",
    "            except (ValueError, TypeError):\n",
    "                continue  # Skip invalid coordinates\n",
    "\n",
    "# Create GeoDataFrame\n",
    "if waypoints:\n",
    "    wp_gdf = gpd.GeoDataFrame(pd.DataFrame(waypoints), geometry=\"geometry\", crs=\"EPSG:3857\")\n",
    "    print(f\"\\n‚úÖ Successfully parsed {len(wp_gdf)} waypoints\")\n",
    "else:\n",
    "    print(\"üö® No coordinates found. Check if any cell contains [X, Y] format.\")\n"
   ],
   "id": "5bd9424b8753d2b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Match Waypoints with Pre-calculated Distances\n",
   "id": "23076f294f98463f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# If we have waypoint IDs in both datasets, we can match them\n",
    "if 'waypoint_id' in wp_gdf.columns and not waypoints_stopareas_df.empty:\n",
    "    # Merge waypoints with waypoints_stopareas\n",
    "    waypoints_with_distances = pd.merge(\n",
    "        wp_gdf,\n",
    "        waypoints_stopareas_df,\n",
    "        on='waypoint_id',\n",
    "        how='inner'\n",
    "    )\n",
    "\n",
    "    # Merge with stops to get stop coordinates\n",
    "    waypoints_stops_distances = pd.merge(\n",
    "        waypoints_with_distances,\n",
    "        stops_gdf[['stoparea_id', 'stoparea_name', 'geometry']],\n",
    "        on='stoparea_id',\n",
    "        how='inner',\n",
    "        suffixes=('_waypoint', '_stoparea')\n",
    "    )\n",
    "\n",
    "    # Remove duplicates having the same itinerary_id, waypoint_id, and distance\n",
    "    original_count = len(waypoints_stops_distances)\n",
    "    waypoints_stops_distances = waypoints_stops_distances.drop_duplicates(\n",
    "        subset=['stoparea_id', 'waypoint_id', 'distance']\n",
    "    )\n",
    "    removed_count = original_count - len(waypoints_stops_distances)\n",
    "\n",
    "    print(f\"Found {original_count} waypoint-stoparea pairs with pre-calculated distances\")\n",
    "    print(f\"Removed {removed_count} duplicates with the same itinerary_id, waypoint_id, and distance\")\n",
    "    print(f\"Remaining {len(waypoints_stops_distances)} unique waypoint-stoparea pairs\")\n",
    "\n",
    "    if not waypoints_stops_distances.empty:\n",
    "        print(\"Sample of waypoint-stoparea pairs:\")\n",
    "        print(waypoints_stops_distances[['waypoint_id', 'stoparea_id', 'stoparea_name', 'distance']].head())\n",
    "else:\n",
    "    print(\"No waypoint IDs found in both datasets, can't match pre-calculated distances\")\n",
    "\n",
    "    # For demonstration, we'll select a few waypoints and stops to calculate distances\n",
    "    # In a real scenario, you might want to use a different approach\n",
    "    sample_waypoints = wp_gdf.head(5)\n",
    "    sample_stops = stops_gdf.head(5)\n",
    "\n",
    "    print(f\"Selected {len(sample_waypoints)} sample waypoints and {len(sample_stops)} sample stops for distance calculation\")\n",
    "\n",
    "    # Create a DataFrame with all combinations of waypoints and stops\n",
    "    waypoints_stops_pairs = []\n",
    "\n",
    "    for wp_idx, wp_row in sample_waypoints.iterrows():\n",
    "        for stop_idx, stop_row in sample_stops.iterrows():\n",
    "            waypoints_stops_pairs.append({\n",
    "                'waypoint_geometry': wp_row.geometry,\n",
    "                'stoparea_id': stop_row.stoparea_id,\n",
    "                'stoparea_name': stop_row.stoparea_name,\n",
    "                'stoparea_geometry': stop_row.geometry\n",
    "            })\n",
    "\n",
    "    waypoints_stops_distances = pd.DataFrame(waypoints_stops_pairs)\n",
    "\n",
    "    print(f\"Created {len(waypoints_stops_distances)} waypoint-stoparea pairs for distance calculation\")\n"
   ],
   "id": "fe8f433ecef9b259",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Calculate Distances using routingpy with OpenRouteService API\n",
   "id": "5ec08c3665cebfc3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from routingpy import ORS\n",
    "from pyproj import Transformer\n",
    "import math\n",
    "\n",
    "# Function to convert EPSG:3857 to EPSG:4326 (lat/lon)\n",
    "def convert_to_latlon(point):\n",
    "    \"\"\"Convert a point from EPSG:3857 to EPSG:4326 (lat/lon)\"\"\"\n",
    "    transformer = Transformer.from_crs('EPSG:3857', 'EPSG:4326', always_xy=True)\n",
    "    lon, lat = transformer.transform(point.x, point.y)\n",
    "    return lat, lon\n",
    "\n",
    "# Function to calculate straight-line distance using Haversine formula\n",
    "def calculate_haversine_distance(point1, point2):\n",
    "    \"\"\"\n",
    "    Calculate the great-circle distance between two points on Earth using the Haversine formula.\n",
    "\n",
    "    Args:\n",
    "        point1: Tuple of (latitude, longitude) for the first point\n",
    "        point2: Tuple of (latitude, longitude) for the second point\n",
    "\n",
    "    Returns:\n",
    "        Distance in kilometers\n",
    "    \"\"\"\n",
    "    # Earth radius in kilometers\n",
    "    R = 6371.0\n",
    "\n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lat1 = math.radians(point1[0])\n",
    "    lon1 = math.radians(point1[1])\n",
    "    lat2 = math.radians(point2[0])\n",
    "    lon2 = math.radians(point2[1])\n",
    "\n",
    "    # Haversine formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = math.sin(dlat / 2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    distance = R * c\n",
    "\n",
    "    return distance\n",
    "\n",
    "# Set up OpenRouteService client\n",
    "# You need to get an API key from https://openrouteservice.org/dev/#/signup\n",
    "# Replace 'your_api_key' with your actual API key\n",
    "ors_api_key = 'xxx'  # Replace with your actual API key\n",
    "ors_client = ORS(api_key=ors_api_key)\n",
    "\n",
    "# Function to calculate route distance between two points\n",
    "def calculate_route_distance(start_point, end_point, profile='foot-walking'):\n",
    "    \"\"\"\n",
    "    Calculate the route distance between two points using OpenRouteService.\n",
    "\n",
    "    Args:\n",
    "        start_point: Tuple of (latitude, longitude) for the start point\n",
    "        end_point: Tuple of (latitude, longitude) for the end point\n",
    "        profile: Routing profile ('foot-walking' or 'driving-car')\n",
    "\n",
    "    Returns:\n",
    "        Distance in kilometers\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get route\n",
    "        route = ors_client.directions(\n",
    "            locations=[\n",
    "                [start_point[1], start_point[0]],  # [lon, lat] for ORS\n",
    "                [end_point[1], end_point[0]]\n",
    "            ],\n",
    "            profile=profile,\n",
    "            format='geojson'\n",
    "        )\n",
    "\n",
    "        # Extract distance in kilometers\n",
    "        distance_km = route.distance / 1000\n",
    "\n",
    "        return distance_km\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating route: {e}\")\n",
    "        return None\n",
    "\n",
    "# Calculate distances for each waypoint-stoparea pair\n",
    "# Note: This will make API calls, which might be rate-limited\n",
    "# For demonstration, we'll calculate for a small sample\n",
    "sample_size = min(100, len(waypoints_stops_distances))\n",
    "# Sort by distance in descending order to get the pairs with the largest distances first\n",
    "# if 'distance' in waypoints_stops_distances.columns:\n",
    "#     waypoints_stops_distances = waypoints_stops_distances.sort_values(by='distance', ascending=False)\n",
    "# sample_pairs = waypoints_stops_distances.head(sample_size)\n",
    "sample_pairs = waypoints_stops_distances.sample(sample_size)\n",
    "\n",
    "results = []\n",
    "\n",
    "for idx, row in sample_pairs.iterrows():\n",
    "    # Get waypoint and stoparea geometries\n",
    "    if 'geometry_waypoint' in row:\n",
    "        waypoint_geom = row.geometry_waypoint\n",
    "        stoparea_geom = row.geometry_stoparea\n",
    "    else:\n",
    "        waypoint_geom = row.waypoint_geometry\n",
    "        stoparea_geom = row.stoparea_geometry\n",
    "\n",
    "    # Convert to lat/lon\n",
    "    waypoint_latlon = convert_to_latlon(waypoint_geom)\n",
    "    stoparea_latlon = convert_to_latlon(stoparea_geom)\n",
    "\n",
    "    # Get pre-calculated distance if available\n",
    "    precalculated_distance = row.get('distance', None)\n",
    "\n",
    "    # Calculate straight-line distance using Haversine formula\n",
    "    straight_line_distance = calculate_haversine_distance(waypoint_latlon, stoparea_latlon)\n",
    "\n",
    "    # Calculate route distances\n",
    "    # Note: use the API key\n",
    "    sleep(4)\n",
    "    foot_distance = calculate_route_distance(waypoint_latlon, stoparea_latlon, profile='foot-walking')\n",
    "    car_distance = calculate_route_distance(waypoint_latlon, stoparea_latlon, profile='driving-car')\n",
    "\n",
    "    # For demonstration, we'll use dummy values\n",
    "    # foot_distance = precalculated_distance * 0.9 if precalculated_distance else None\n",
    "    # car_distance = precalculated_distance * 1.1 if precalculated_distance else None\n",
    "\n",
    "    results.append({\n",
    "        'waypoint_latlon': waypoint_latlon,\n",
    "        'itinerary_id': row.itinerary_id,\n",
    "        'stoparea_id': row.stoparea_id,\n",
    "        'stoparea_name': row.stoparea_name,\n",
    "        'stoparea_latlon': stoparea_latlon,\n",
    "        'precalculated_distance': precalculated_distance,\n",
    "        'foot_distance': foot_distance,\n",
    "        'car_distance': car_distance,\n",
    "        'straight_line_distance': straight_line_distance\n",
    "    })\n",
    "\n",
    "# Create DataFrame with results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"Distance calculation results:\")\n",
    "print(results_df[['stoparea_id', 'itinerary_id', 'precalculated_distance', 'straight_line_distance', 'foot_distance', 'car_distance']])\n"
   ],
   "id": "ffef9894c13e8425",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Visualize Distance Comparisons\n",
   "id": "a86c622f6fac2352"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Prepare data for visualization\n",
    "if not results_df.empty:\n",
    "    # Remove rows where any of the distance metrics is 0\n",
    "    original_count = len(results_df)\n",
    "    results_df = results_df[\n",
    "        (results_df['foot_distance'] != 0) &\n",
    "        (results_df['car_distance'] != 0) &\n",
    "        (results_df['straight_line_distance'] != 0) &\n",
    "        (results_df['precalculated_distance'] != 0)\n",
    "    ]\n",
    "    removed_count = original_count - len(results_df)\n",
    "    print(f\"Removed {removed_count} rows with zero distances\")\n",
    "    print(f\"Remaining {len(results_df)} rows\")\n",
    "\n",
    "    # Melt the DataFrame to have distance type as a variable\n",
    "    plot_data = pd.melt(\n",
    "        results_df,\n",
    "        id_vars=['stoparea_name'],\n",
    "        value_vars=['precalculated_distance', 'foot_distance', 'car_distance', 'straight_line_distance'],\n",
    "        var_name='distance_type',\n",
    "        value_name='distance_km'\n",
    "    )\n",
    "\n",
    "    # Replace distance_type values with more readable labels\n",
    "    plot_data['distance_type'] = plot_data['distance_type'].replace({\n",
    "        'precalculated_distance': 'Pre-calculated',\n",
    "        'foot_distance': 'Walking (ORS)',\n",
    "        'car_distance': 'Driving (ORS)',\n",
    "        'straight_line_distance': 'Straight-line (Haversine)'\n",
    "    })\n",
    "\n",
    "    # Create a grouped bar chart\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot\n",
    "    ax = plt.subplot(111)\n",
    "    for i, distance_type in enumerate(['Pre-calculated', 'Walking (ORS)', 'Driving (ORS)', 'Straight-line (Haversine)']):\n",
    "        data = plot_data[plot_data['distance_type'] == distance_type]\n",
    "        x = np.arange(len(data))\n",
    "        width = 0.2  # Reduced width to fit 4 bars\n",
    "        ax.bar(x + i*width - 0.3, data['distance_km'], width, label=distance_type)\n",
    "\n",
    "    # Add labels and legend\n",
    "    ax.set_xlabel('Bus Stop')\n",
    "    ax.set_ylabel('Distance (km)')\n",
    "    ax.set_title('Distance Comparison: Pre-calculated vs. OpenRouteService')\n",
    "    ax.set_xticks(np.arange(len(results_df)))\n",
    "    ax.set_xticklabels(results_df['stoparea_name'], rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No data available for visualization\")\n"
   ],
   "id": "347cf48ae677a41f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "87615b66156d326f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6. Summary and Conclusions\n",
   "id": "fd089dde41a29b73"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calculate statistics\n",
    "if not results_df.empty:\n",
    "    # Calculate differences between pre-calculated and calculated distances\n",
    "    if 'precalculated_distance' in results_df.columns:\n",
    "        #\n",
    "        # # After calculating the mean values\n",
    "        # straight_line_diff_pct_mean = results_df['straight_line_diff_pct'].mean()\n",
    "        # foot_diff_pct_mean = results_df['foot_diff_pct'].mean()\n",
    "        # car_diff_pct_mean = results_df['car_diff_pct'].mean()\n",
    "        #\n",
    "        # # Calculate absolute percentage differences to determine which is closest\n",
    "        # abs_straight_line_diff = abs(straight_line_diff_pct_mean)\n",
    "        # abs_foot_diff = abs(foot_diff_pct_mean)\n",
    "        # abs_car_diff = abs(car_diff_pct_mean)\n",
    "        #\n",
    "        # # Determine which distance type is closest to precalculated value\n",
    "        # closest_type = \"car\" if abs_car_diff < abs_foot_diff else \"foot\"\n",
    "        # closest_diff = min(abs_car_diff, abs_foot_diff)\n",
    "        #\n",
    "        # # Conclusions\n",
    "        # print(\"\\nConclusions:\")\n",
    "        # print(\"1. The pre-calculated distances in the SQL dump are consistently larger than all other calculated distances (straight-line, walking, and driving).\")\n",
    "        # print(f\"2. Straight-line distances show the largest difference, being on average {abs_straight_line_diff:.1f}% shorter than pre-calculated distances.\")\n",
    "        # print(f\"3. Walking distances are on average {abs_foot_diff:.1f}% shorter than pre-calculated distances.\")\n",
    "        # print(f\"4. Car distances are on average {abs_car_diff:.1f}% shorter than pre-calculated distances.\")\n",
    "        # print(f\"5. {closest_type.capitalize()} distances are closest to the pre-calculated values, with only {closest_diff:.1f}% difference.\")\n",
    "        # print(\"6. The significant differences suggest that the pre-calculated distances may be using different routing algorithms, include additional factors, or potentially overestimate the actual distances.\")\n",
    "        #\n",
    "        #\n",
    "\n",
    "\n",
    "\n",
    "        #\n",
    "        # # Differences with pre-calculated distance\n",
    "        # results_df['foot_diff'] = results_df['precalculated_distance'] - results_df['foot_distance']\n",
    "        # results_df['car_diff'] =  results_df['precalculated_distance'] - results_df['car_distance']\n",
    "        # results_df['straight_line_diff'] = results_df['precalculated_distance'] - results_df['straight_line_distance']\n",
    "        results_df['foot_diff'] = abs(results_df['foot_distance'] - results_df['precalculated_distance'])\n",
    "        results_df['car_diff'] =  abs(results_df['car_distance'] - results_df['precalculated_distance'])\n",
    "        results_df['straight_line_diff'] = abs(results_df['straight_line_distance'] - results_df['precalculated_distance'])\n",
    "        #\n",
    "        # # Percentage differences with pre-calculated distance\n",
    "        # results_df['foot_diff_pct'] = (results_df['foot_diff'] / results_df['precalculated_distance']) * 100\n",
    "        # results_df['car_diff_pct'] = (results_df['car_diff'] / results_df['precalculated_distance']) * 100\n",
    "        # results_df['straight_line_diff_pct'] = (results_df['straight_line_diff'] / results_df['precalculated_distance']) * 100\n",
    "        #\n",
    "        # Summary statistics\n",
    "        print(\"Summary Statistics:\")\n",
    "        print(\"\\nAbsolute Differences from Pre-calculated Distance (km):\")\n",
    "        print(results_df[['straight_line_diff', 'foot_diff', 'car_diff']].describe())\n",
    "        #\n",
    "        # print(\"\\nPercentage Differences from Pre-calculated Distance (%):\")\n",
    "        # print(results_df[['straight_line_diff_pct', 'foot_diff_pct', 'car_diff_pct']].describe())\n",
    "        #\n",
    "        # # Calculate ratio of precalc to route distances\n",
    "        # results_df['precalc_to_foot_ratio'] = results_df['precalculated_distance'] / results_df['foot_distance']\n",
    "        # results_df['precalc_to_car_ratio'] = results_df['precalculated_distance'] / results_df['car_distance']\n",
    "        #\n",
    "        # print(\"\\nRatio of precalc to Route Distances:\")\n",
    "        # print(results_df[['precalc_to_foot_ratio', 'precalc_to_car_ratio']].describe())\n",
    "        #\n",
    "        # # Get mean values from the statistics\n",
    "        # straight_line_diff_pct_mean = results_df['straight_line_diff_pct'].mean()\n",
    "        # foot_diff_pct_mean = results_df['foot_diff_pct'].mean()\n",
    "        # car_diff_pct_mean = results_df['car_diff_pct'].mean()\n",
    "        #\n",
    "        # # Conclusions\n",
    "        # print(\"\\nConclusions:\")\n",
    "        # print(\"1. The pre-calculated distances in the SQL dump are consistently larger than all other calculated distances (straight-line, walking, and driving).\")\n",
    "        # print(f\"2. Straight-line distances show the largest difference, being on average {abs(straight_line_diff_pct_mean):.1f}% shorter than pre-calculated distances.\")\n",
    "        # print(f\"3. Walking distances are on average {abs(foot_diff_pct_mean):.1f}% shorter than pre-calculated distances.\")\n",
    "        # print(f\"4. Car distances are on average {abs(car_diff_pct_mean):.1f}% shorter than pre-calculated distances, making them closest to the pre-calculated values.\")\n",
    "        # print(\"5. The significant differences suggest that the pre-calculated distances may be using different routing algorithms, include additional factors, or potentially overestimate the actual distances.\")\n",
    "else:\n",
    "    print(\"No data available for analysis\")\n"
   ],
   "id": "99be4afd1fee88fc",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
