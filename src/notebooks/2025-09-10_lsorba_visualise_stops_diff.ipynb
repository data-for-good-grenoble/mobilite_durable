{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d885033858fa2534",
   "metadata": {},
   "source": [
    "üöå Projet MDM - Mobilit√© Durable en Montagne ‚õ∞Ô∏è\n",
    "\n",
    "*Author: Laurent Sorba*\n",
    "\n",
    "*Date: 14/09/2025*\n",
    "\n",
    "**Description :**\n",
    "\n",
    "This notebook combines up to 3 stop files (GeoParquets or GeoJSONs), reproject inputs to EPSG:3857 if needed,\n",
    "cluster by proximity, represent cluster by centroid or mediod, and plot the result on an interactive map.\n",
    "\n",
    "See https://github.com/data-for-good-grenoble/mobilite_durable/issues/37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0fe6de09c8b7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import geopandas as gpd\n",
    "\n",
    "\n",
    "def plot_clusters_interactive(\n",
    "    agg_gdf: gpd.GeoDataFrame,\n",
    "    title: str = None,\n",
    "    point_radius: int = 5,\n",
    "    tiles: str = \"OpenStreetMap\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Display an interactive Leaflet map (zoom/scroll) using folium.\n",
    "    - agg_gdf: GeoDataFrame with columns [geometry(Point in EPSG:3857), colour, name(optional)]\n",
    "    - title: optional map title (added as child HTML)\n",
    "    - point_radius: circle marker radius in pixels\n",
    "    - tiles: folium base tiles name or URL template\n",
    "    Returns the folium.Map object, which renders in notebooks.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert to WGS84 for web maps\n",
    "    gdf_ll = agg_gdf.to_crs(EPSG_WGS84)\n",
    "\n",
    "    # Determine initial center\n",
    "    if not gdf_ll.empty:\n",
    "        center = [gdf_ll.geometry.y.mean(), gdf_ll.geometry.x.mean()]\n",
    "    else:\n",
    "        center = [45.1885, 5.7245]  # Grenoble as default\n",
    "\n",
    "    m = folium.Map(location=center, zoom_start=8, tiles=tiles)\n",
    "\n",
    "    # Optionally add a title\n",
    "    if title:\n",
    "        title_html = f'<h4 style=\"position: fixed; top: 10px; left: 50px; z-index: 9999; background: rgba(255,255,255,0.8); padding: 6px 10px; margin: 0;\">{title}</h4>'\n",
    "        m.get_root().html.add_child(folium.Element(title_html))\n",
    "\n",
    "    # Group by colours for consistency\n",
    "    colour_labels = [\n",
    "        (\"green\", \"in A+B+C (green)\"),\n",
    "        (\"blue\", \"in any 2 sources (blue)\"),\n",
    "        (\"orange\", \"only in TDG (orange)\"),\n",
    "        (\"yellow\", \"only in OSM (yellow)\"),\n",
    "        (\"brown\", \"only in C2C (brown)\"),\n",
    "        (\"gray\", \"none/other (gray)\"),\n",
    "    ]\n",
    "\n",
    "    bounds = []\n",
    "    for colour, label in colour_labels:\n",
    "        sub = gdf_ll[gdf_ll[\"colour\"] == colour]\n",
    "        if len(sub) == 0:\n",
    "            continue\n",
    "        fg = folium.FeatureGroup(name=label, show=True)\n",
    "        for _, row in sub.iterrows():\n",
    "            pt = row.geometry\n",
    "            popup_txt = []\n",
    "\n",
    "            if \"names\" in row:\n",
    "                popup_txt.append(f\"names: {','.join(row['names'])}\")\n",
    "            if \"ids\" in row:\n",
    "                popup_txt.append(f\"ids: {','.join(row['ids'])}\")\n",
    "            if \"cluster\" in row:\n",
    "                popup_txt.append(f\"cluster: {row['cluster']}\")\n",
    "            if \"agencies\" in row:\n",
    "                popup_txt.append(f\"agencies: {','.join(row['agencies'])}\")\n",
    "            if \"sources\" in row:\n",
    "                popup_txt.append(f\"sources: {','.join(row['sources'])}\")\n",
    "            if \"count\" in row:\n",
    "                popup_txt.append(f\"count: {row['count']}\")\n",
    "\n",
    "            popup = \"<br>\".join(popup_txt) if popup_txt else None\n",
    "\n",
    "            folium.CircleMarker(\n",
    "                location=(pt.y, pt.x),\n",
    "                radius=point_radius,\n",
    "                color=colour,\n",
    "                fill=True,\n",
    "                fill_opacity=0.8,\n",
    "                fill_color=colour,\n",
    "                popup=popup,\n",
    "            ).add_to(fg)\n",
    "            bounds.append((pt.y, pt.x))\n",
    "        fg.add_to(m)\n",
    "\n",
    "    folium.LayerControl(collapsed=False).add_to(m)\n",
    "\n",
    "    # Fit bounds if we have any points\n",
    "    if bounds:\n",
    "        m.fit_bounds(bounds, padding=(20, 20))\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb25569e15c69ec",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "from pathlib import Path\n",
    "from typing import Sequence\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.geometry import MultiPoint\n",
    "from shapely.geometry.point import Point\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "from src.settings import EPSG_WEB_MERCATOR, EPSG_WGS84\n",
    "\n",
    "# Default colour mapping\n",
    "\"\"\"\n",
    "Colours:\n",
    "- green = in A+B+C\n",
    "- blue  = in any 2 sources\n",
    "- orange/yellow/brown = only in TDG / OSM / C2C\n",
    "\"\"\"\n",
    "\n",
    "COLOUR_SINGLE = {\"TDG\": \"orange\", \"OSM\": \"yellow\", \"C2C\": \"brown\"}\n",
    "COLOUR_TWO = \"blue\"\n",
    "COLOUR_THREE = \"green\"\n",
    "COLOUR_NONE = \"gray\"\n",
    "\n",
    "TARGET_EPSG = EPSG_WEB_MERCATOR  # metric CRS for clustering and output\n",
    "\n",
    "\n",
    "def read_and_ensure_crs(path: str, label: str, target_epsg: str = TARGET_EPSG):\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"{path} not found\")\n",
    "\n",
    "    # Choose reader based on extension (GeoJSON vs GeoParquet)\n",
    "    suffix = p.suffix.lower()\n",
    "    if suffix in {\".parquet\", \".pq\", \".geoparquet\", \".gpq\"}:\n",
    "        gdf = gpd.read_parquet(str(p))\n",
    "    else:\n",
    "        gdf = gpd.read_file(str(p))\n",
    "\n",
    "    gdf = gdf[gdf.geometry.type == \"Point\"].copy()\n",
    "    if gdf.empty:\n",
    "        raise ValueError(f\"{path} contains no Point geometries\")\n",
    "    if not gdf.crs:\n",
    "        # OSM data has no CRS defined, so we assume it's WGS84\n",
    "        gdf.set_crs(EPSG_WGS84, inplace=True)\n",
    "\n",
    "    # reproject to target if needed\n",
    "    if gdf.crs != target_epsg:\n",
    "        gdf = gdf.to_crs(target_epsg)\n",
    "\n",
    "    gdf[\"source\"] = label\n",
    "\n",
    "    def _strip_accents(s: str) -> str:\n",
    "        # Robust to NaN/None and vectorised via .map below\n",
    "        if pd.isna(s):\n",
    "            return \"\"\n",
    "        nfkd = unicodedata.normalize(\"NFKD\", str(s))\n",
    "        return \"\".join(c for c in nfkd if not unicodedata.combining(c))\n",
    "\n",
    "    # Normalise stop name column: unify 'name' and 'stop_name' into 'stop_name'\n",
    "    try:\n",
    "        if \"stop_name\" in gdf.columns and \"name\" in gdf.columns:\n",
    "            # Prefer non-empty stop_name, otherwise fall back to name\n",
    "            sn = gdf[\"stop_name\"].astype(str)\n",
    "            nm = gdf[\"name\"].astype(str)\n",
    "            use_sn = sn.str.strip().astype(bool)\n",
    "            stop_name_series = sn.where(use_sn, nm)\n",
    "        elif \"stop_name\" not in gdf.columns and \"name\" in gdf.columns:\n",
    "            stop_name_series = gdf[\"name\"].astype(str)\n",
    "        else:\n",
    "            stop_name_series = gdf.get(\"stop_name\", pd.Series(\"\", index=gdf.index)).astype(str)\n",
    "\n",
    "        # Vectorised normalisation\n",
    "        stop_name_norm = stop_name_series.map(_strip_accents).str.lower().str.strip()\n",
    "\n",
    "        # Case-insensitive canonicalization\n",
    "        key_ci = stop_name_norm.str.casefold()\n",
    "        canon_map = stop_name_norm.groupby(key_ci).first()\n",
    "        gdf[\"stop_name\"] = key_ci.map(canon_map)\n",
    "\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Normalise agency_name and network\n",
    "    try:\n",
    "        if \"agency_name\" in gdf.columns and \"network\" in gdf.columns:\n",
    "            gdf[\"agency_name\"] = gdf[\"network\"]\n",
    "        elif \"agency_name\" not in gdf.columns and \"network\" in gdf.columns:\n",
    "            gdf[\"agency_name\"] = gdf[\"network\"]\n",
    "        # else: keep existing agency_name as is\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Normalise stop id column: unify 'id' and 'stop_id' into 'stop_id'\n",
    "    try:\n",
    "        if \"stop_id\" in gdf.columns and \"id\" in gdf.columns:\n",
    "            gdf[\"stop_id\"] = gdf[\"id\"].fillna(\"\").astype(str)\n",
    "        elif \"stop_id\" not in gdf.columns and \"gtfs_id\" in gdf.columns:\n",
    "            gdf[\"stop_id\"] = gdf[\"gtfs_id\"].fillna(\"\").astype(str)\n",
    "        elif \"stop_id\" not in gdf.columns and \"osm_id\" in gdf.columns:\n",
    "            gdf[\"stop_id\"] = gdf[\"osm_id\"].fillna(\"\").astype(str)\n",
    "        # else: keep existing stop_id as is\n",
    "    except Exception:\n",
    "        pass\n",
    "    return gdf\n",
    "\n",
    "\n",
    "def medoid_point(points: Sequence[Point]) -> Point:\n",
    "    coords = np.array([[p.x, p.y] for p in points])\n",
    "    if len(coords) == 1:\n",
    "        return points[0]\n",
    "    D = np.sqrt(((coords[:, None, :] - coords[None, :, :]) ** 2).sum(axis=2))\n",
    "    idx = D.sum(axis=1).argmin()\n",
    "    return points[int(idx)]\n",
    "\n",
    "\n",
    "def cluster_and_represent(gdf_all: gpd.GeoDataFrame, tolerance: float, use_medoid: bool):\n",
    "    # gdf_all is expected in TARGET_EPSG (metric)\n",
    "    coords = np.array([[pt.x, pt.y] for pt in gdf_all.geometry])\n",
    "    db = DBSCAN(eps=tolerance, min_samples=1, metric=\"euclidean\").fit(coords)\n",
    "    gdf_all = gdf_all.copy()\n",
    "    gdf_all[\"cluster\"] = db.labels_\n",
    "    clusters = []\n",
    "    for cid, sub in gdf_all.groupby(\"cluster\"):\n",
    "        geoms = list(sub.geometry)\n",
    "        sources = sorted(sub[\"source\"].unique().tolist())\n",
    "        ids = sub[\"stop_id\"].tolist() if \"stop_id\" in sub.columns else list(sub.index)\n",
    "        agencies = sorted(\n",
    "            {str(x).strip() for x in sub[\"agency_name\"].dropna() if str(x).strip()}\n",
    "        )\n",
    "        names = sorted({str(x).strip() for x in sub[\"stop_name\"].dropna() if str(x).strip()})\n",
    "        rep_pt = medoid_point(geoms) if use_medoid else MultiPoint(geoms).centroid\n",
    "\n",
    "        clusters.append(\n",
    "            {\n",
    "                \"cluster\": int(cid),\n",
    "                \"geometry\": rep_pt,\n",
    "                \"ids\": ids,\n",
    "                \"agencies\": agencies,\n",
    "                \"count\": len(sub),\n",
    "                \"sources\": sources,\n",
    "                \"names\": names,\n",
    "            }\n",
    "        )\n",
    "    agg = gpd.GeoDataFrame(clusters, geometry=\"geometry\", crs=gdf_all.crs)\n",
    "\n",
    "    def pick_colour(sources: Sequence[str]) -> str:\n",
    "        n = len(sources)\n",
    "        if n >= 3:\n",
    "            return COLOUR_THREE\n",
    "        if n == 2:\n",
    "            return COLOUR_TWO\n",
    "        if n == 1:\n",
    "            return COLOUR_SINGLE.get(sources[0], COLOUR_NONE)\n",
    "        return COLOUR_NONE\n",
    "\n",
    "    agg[\"colour\"] = agg[\"sources\"].apply(pick_colour)\n",
    "    agg[\"in_TDG\"] = agg[\"sources\"].apply(lambda s: \"TDG\" in s)\n",
    "    agg[\"in_OSM\"] = agg[\"sources\"].apply(lambda s: \"OSM\" in s)\n",
    "    agg[\"in_C2C\"] = agg[\"sources\"].apply(lambda s: \"C2C\" in s)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c02f20b7501916",
   "metadata": {},
   "source": [
    "## Explanation of Medoid and Centroid\n",
    "\n",
    "The *medoid* is the point that minimises the total distance to all other points in a dataset, making it robust to outliers. In contrast, the *centroid* is the average of the coordinates of all points, but it can be influenced by extreme values and does not always correspond to an actual point in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80122289a547c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the input GeoJSONs or GeoParquet (can be 1 to 3 sources)\n",
    "a_path = Path(\"../data/transportdatagouv/stops_38.parquet\")\n",
    "b_path = Path(\"../data/OSM/bus_stops_isere.parquet\")\n",
    "c_path = None  # Path(\"../data/C2C/\n",
    "tol_m = 200.0  # in meters\n",
    "use_medoid = True\n",
    "\n",
    "gdfs = []\n",
    "for pth, lab in ((a_path, \"TDG\"), (b_path, \"OSM\"), (c_path, \"C2C\")):\n",
    "    if pth:\n",
    "        gdfs.append(read_and_ensure_crs(pth, lab, target_epsg=TARGET_EPSG))\n",
    "gdf_all = gpd.GeoDataFrame(pd.concat(gdfs, ignore_index=True, sort=False), crs=gdfs[0].crs)\n",
    "res = cluster_and_represent(gdf_all, tol_m, use_medoid)\n",
    "out_nb = res[\n",
    "    [\n",
    "        \"geometry\",\n",
    "        \"cluster\",\n",
    "        \"ids\",\n",
    "        \"names\",\n",
    "        \"agencies\",\n",
    "        \"count\",\n",
    "        \"sources\",\n",
    "        \"in_TDG\",\n",
    "        \"in_OSM\",\n",
    "        \"in_C2C\",\n",
    "        \"colour\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bee20dd0352900b",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = plot_clusters_interactive(out_nb, title=\"Stops diff clusters (coloured by presence)\")\n",
    "m  # display in notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
