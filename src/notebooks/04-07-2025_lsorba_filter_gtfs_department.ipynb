{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2efa3ab4f0795cbf",
   "metadata": {},
   "source": [
    "üöå Projet MDM - Mobilit√© Durable en Montagne ‚õ∞Ô∏è\n",
    "\n",
    "*Author : Laurent Sorba*\n",
    "\n",
    "*Date : 04/07/2025*\n",
    "\n",
    "**Description :**\n",
    "\n",
    "This Jupyter Notebook analyses the accessibility of the itineraries by measuring proximity to public transport stops, using pandas/geopandas to parse waypoints from the C2C CSV export for Is√®re `List_iti_D4G_isre.csv` and extract bus stop locations from a PostgreSQL SQL C2C dump  `UTF-8dump-c2corg-202505050900.sql.zip`. It performs spatial analysis to count itineraries within 0.5km‚Äì5km zones around bus stops using the EPSG:3857 coordinate system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff97032391a64f24",
   "metadata": {},
   "source": "## D√©finition des fonctions"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f63960331f4e53c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T12:58:06.454773Z",
     "start_time": "2025-07-04T12:58:05.584328Z"
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import requests\n",
    "from shapely.geometry import Point\n",
    "\n",
    "\n",
    "# 1. T√©l√©charger et extraire les donn√©es GTFS\n",
    "def download_gtfs_data(gtfs_url):\n",
    "    \"\"\"T√©l√©charge et extrait les donn√©es GTFS\"\"\"\n",
    "    print(f\"=== T√©l√©charge les donn√©es GTFS depuis {gtfs_url} ===\")\n",
    "    response = requests.get(gtfs_url)\n",
    "    with zipfile.ZipFile(io.BytesIO(response.content)) as zip_file:\n",
    "        # Extraire les fichiers n√©cessaires\n",
    "        stops_df = pd.read_csv(zip_file.open(\"stops.txt\"))\n",
    "        print(f\"Charg√© {len(stops_df)} arr√™ts\")\n",
    "        routes_df = pd.read_csv(zip_file.open(\"routes.txt\"))\n",
    "        print(f\"Charg√© {len(routes_df)} lignes\")\n",
    "\n",
    "        # Autres fichiers GTFS si n√©cessaire\n",
    "        try:\n",
    "            stop_times_df = pd.read_csv(zip_file.open(\"stop_times.txt\"))\n",
    "            print(f\"(Charg√© {len(routes_df)} stop_times)\")\n",
    "            trips_df = pd.read_csv(zip_file.open(\"trips.txt\"))\n",
    "            print(f\"(Charg√© {len(routes_df)} trips)\")\n",
    "        except KeyError:\n",
    "            stop_times_df = None\n",
    "            trips_df = None\n",
    "\n",
    "    return stops_df, routes_df, stop_times_df, trips_df\n",
    "\n",
    "\n",
    "# 2. Filtrer les arr√™ts par d√©partement de l'Is√®re par d√©faut\n",
    "def filter_stops_by_department(stops_df, department_code=\"38\"):\n",
    "    \"\"\"Filtre les arr√™ts par code d√©partement\"\"\"\n",
    "    return filter_with_administrative_boundaries(stops_df, department_code)\n",
    "\n",
    "\n",
    "# 3. Filtrer les lignes de transport correspondant\n",
    "def filter_routes_by_stops(routes_df, filtered_stops, trips_df=None, stop_times_df=None):\n",
    "    \"\"\"Filtre les lignes qui desservent les arr√™ts filtr√©s\"\"\"\n",
    "    if trips_df is not None and stop_times_df is not None:\n",
    "        # Trouver les trips qui passent par les arr√™ts filtr√©s\n",
    "        department_stop_ids = filtered_stops[\"stop_id\"].unique()\n",
    "        trips_with_department_stops = stop_times_df[\n",
    "            stop_times_df[\"stop_id\"].isin(department_stop_ids)\n",
    "        ][\"trip_id\"].unique()\n",
    "\n",
    "        # Trouver les routes correspondantes\n",
    "        routes_in_department = trips_df[trips_df[\"trip_id\"].isin(trips_with_department_stops)][\n",
    "            \"route_id\"\n",
    "        ].unique()\n",
    "\n",
    "        filtered_routes = routes_df[routes_df[\"route_id\"].isin(routes_in_department)]\n",
    "    else:\n",
    "        # Si pas de donn√©es de correspondance, retourner toutes les routes\n",
    "        filtered_routes = routes_df\n",
    "\n",
    "    return filtered_routes\n",
    "\n",
    "\n",
    "def filter_with_administrative_boundaries(stops_df, department_code):\n",
    "    \"\"\"\n",
    "    Filtre les arr√™ts de transport en utilisant les limites administratives pr√©cises\n",
    "    du d√©partement de l'Is√®re\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Charger les limites administratives du d√©partement\n",
    "    department_boundary = download_department_boundary(department_code)\n",
    "\n",
    "    if department_boundary is None:\n",
    "        print(\n",
    "            \"Impossible de t√©l√©charger les limites administratives. Utilisation du filtrage par coordonn√©es.\"\n",
    "        )\n",
    "        exit\n",
    "\n",
    "    # 2. Convertir les arr√™ts en GeoDataFrame\n",
    "    stops_gdf = create_stops_geodataframe(stops_df)\n",
    "\n",
    "    # 3. Filtrer les arr√™ts qui se trouvent dans le d√©partement\n",
    "    filtered_stops = spatial_filter_stops(stops_gdf, department_boundary)\n",
    "\n",
    "    return filtered_stops\n",
    "\n",
    "\n",
    "def download_department_boundary(department_code=\"38\"):\n",
    "    \"\"\"\n",
    "    Charge ou t√©l√©charge les limites administratives du d√©partement de l'Is√®re\n",
    "    \"\"\"\n",
    "\n",
    "    # Utiliser les donn√©es de data.gouv.fr\n",
    "    try:\n",
    "        boundary = load_department_geometry(department_code)\n",
    "        if boundary is not None:\n",
    "            return boundary\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur avec data.gouv.fr: {e}\")\n",
    "\n",
    "    # Fallback : Utiliser des coordonn√©es pr√©d√©finies\n",
    "    try:\n",
    "        boundary = create_isere_boundary_from_coords()\n",
    "        return boundary\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur avec coordonn√©es pr√©d√©finies: {e}\")\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def download_from_data_gouv(file_path):\n",
    "    \"\"\"\n",
    "    T√©l√©charge depuis data.gouv.fr - Contours des d√©partements fran√ßais\n",
    "    \"\"\"\n",
    "    # URL des contours des d√©partements fran√ßais\n",
    "    url = \"https://www.data.gouv.fr/fr/datasets/r/90b9341a-e1f7-4d75-a73c-bbc010c7feeb\"\n",
    "    print(f\"=== T√©l√©charge les contours des d√©partements fran√ßais {url} ===\")\n",
    "    try:\n",
    "        # T√©l√©charger le GeoJSON\n",
    "        response = requests.get(url, timeout=30)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # R√©cup√©rer le contenu JSON\n",
    "        geojson_data = response.json()\n",
    "\n",
    "        # Cr√©er le r√©pertoire s'il n'existe pas\n",
    "        file_path = Path(file_path)\n",
    "        file_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Sauvegarder dans le fichier\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(geojson_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "        print(f\"Fichier sauvegard√© avec succ√®s : {file_path}\")\n",
    "        print(f\"Nombre de d√©partements : {len(geojson_data['features'])}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du t√©l√©chargement depuis data.gouv.fr: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def load_department_geometry(department_code=\"38\"):\n",
    "    \"\"\"\n",
    "    T√©l√©charge depuis data.gouv.fr - Contours des d√©partements fran√ßais\n",
    "    \"\"\"\n",
    "    # URL des contours des d√©partements fran√ßais\n",
    "    file = \"../data/transportdatagouv/contour-des-departements.geojson\"\n",
    "    print(f\"=== Charge les contours des d√©partements fran√ßais depuis le fichier {file} ===\")\n",
    "\n",
    "    try:\n",
    "        # Test if file exists\n",
    "        if not Path(file).is_file():\n",
    "            print(f\"-> Le fichier n'existe pas, t√©l√©chargement n√©cessaire.\")\n",
    "            download_from_data_gouv(file)\n",
    "\n",
    "        # Charger le GeoJSON\n",
    "        france_departments = gpd.read_file(file)\n",
    "\n",
    "        # Filtrer sur un d√©partement\n",
    "        department_boundary = france_departments[france_departments[\"code\"] == department_code]\n",
    "\n",
    "        if not department_boundary.empty:\n",
    "            return department_boundary.iloc[0].geometry\n",
    "        else:\n",
    "            print(f\"D√©partement {department_code} non trouv√© dans les donn√©es\")\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du chargement des contours des d√©partements: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def create_isere_boundary_from_coords():\n",
    "    \"\"\"\n",
    "    Cr√©e une approximation des limites de l'Is√®re √† partir de coordonn√©es connues\n",
    "    \"\"\"\n",
    "    from shapely.geometry import Polygon\n",
    "\n",
    "    print(f\"=== Fallback: Utiliser des coordonn√©es pr√©d√©finies de l'Is√®re ===\")\n",
    "\n",
    "    # Coordonn√©es approximatives des limites de l'Is√®re\n",
    "    isere_coords = [\n",
    "        (5.2, 44.8),  # Sud-Ouest\n",
    "        (6.3, 44.8),  # Sud-Est\n",
    "        (6.3, 45.9),  # Nord-Est\n",
    "        (5.2, 45.9),  # Nord-Ouest\n",
    "        (5.2, 44.8),  # Fermeture du polygone\n",
    "    ]\n",
    "\n",
    "    boundary = Polygon(isere_coords)\n",
    "    return boundary\n",
    "\n",
    "\n",
    "def create_stops_geodataframe(stops_df):\n",
    "    \"\"\"\n",
    "    Convertit le DataFrame des arr√™ts en GeoDataFrame\n",
    "    \"\"\"\n",
    "    # Cr√©er des objets Point √† partir des coordonn√©es\n",
    "    geometry = [Point(xy) for xy in zip(stops_df[\"stop_lon\"], stops_df[\"stop_lat\"])]\n",
    "\n",
    "    # Cr√©er le GeoDataFrame\n",
    "    stops_gdf = gpd.GeoDataFrame(\n",
    "        stops_df,\n",
    "        geometry=geometry,\n",
    "        crs=\"EPSG:4326\",  # WGS84\n",
    "    )\n",
    "\n",
    "    return stops_gdf\n",
    "\n",
    "\n",
    "def spatial_filter_stops(stops_gdf, department_boundary):\n",
    "    \"\"\"\n",
    "    Filtre spatialement les arr√™ts qui se trouvent dans les limites du d√©partement\n",
    "    \"\"\"\n",
    "    print(\n",
    "        f\"=== Filtre spatialement les arr√™ts qui se trouvent dans les limites du d√©partement ===\"\n",
    "    )\n",
    "    # Cr√©er un GeoDataFrame pour la limite du d√©partement\n",
    "    if hasattr(department_boundary, \"crs\"):\n",
    "        boundary_gdf = gpd.GeoDataFrame(\n",
    "            [1], geometry=[department_boundary], crs=department_boundary.crs\n",
    "        )\n",
    "    else:\n",
    "        boundary_gdf = gpd.GeoDataFrame([1], geometry=[department_boundary], crs=\"EPSG:4326\")\n",
    "\n",
    "    # S'assurer que les deux GeoDataFrames ont le m√™me CRS\n",
    "    if stops_gdf.crs != boundary_gdf.crs:\n",
    "        stops_gdf = stops_gdf.to_crs(boundary_gdf.crs)\n",
    "\n",
    "    # Filtrage spatial : garder les arr√™ts qui intersectent avec la limite\n",
    "    filtered_stops = gpd.sjoin(stops_gdf, boundary_gdf, how=\"inner\", predicate=\"within\")\n",
    "\n",
    "    # Supprimer les colonnes ajout√©es par sjoin\n",
    "    filtered_stops = filtered_stops.drop(columns=[\"index_right\"], errors=\"ignore\")\n",
    "\n",
    "    return filtered_stops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd37561dfba98b29",
   "metadata": {},
   "source": "## D√©finition des variables"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "759a8ca964c89f38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T12:59:32.228670Z",
     "start_time": "2025-07-04T12:59:32.224871Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# URLs des donn√©es GTFS contenant l'Is√®re\n",
    "gtfs_sources = {\n",
    "    # Definition https://transport.data.gouv.fr/datasets/agregat-oura\n",
    "    \"agregat-oura\": \"https://api.oura3.cityway.fr/dataflow/offre-tc/download?provider=OURA&dataFormat=GTFS&dataProfil=OPENDATA\",\n",
    "    # Definition https://transport.data.gouv.fr/datasets/reseau-cars-region-isere-38\n",
    "    \"reseau-cars-region-isere-38\": \"https://www.itinisere.fr/fr/donnees-open-data/169/OpenData/Download?fileName=CG38.GTFS.zip\",\n",
    "    # Definition https://transport.data.gouv.fr/datasets/horaires-theoriques-du-reseau-tag\n",
    "    \"TAG_Grenoble\": \"https://data.mobilites-m.fr/api/gtfs/SEM\",\n",
    "}\n",
    "\n",
    "department_code = \"38\"\n",
    "data_set = \"agregat-oura\"\n",
    "gtfs_url = gtfs_sources[data_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c30d7f4c7f193fef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T12:58:06.653855Z",
     "start_time": "2025-07-04T12:58:06.651764Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Filtrage avec limites administratives du '38' sur 'agregat-oura' ===\n"
     ]
    }
   ],
   "source": [
    "print(f\"=== Filtrage avec limites administratives du '{department_code}' sur '{data_set}' ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca40fb50df4eb675",
   "metadata": {},
   "source": "### T√©l√©charger les donn√©es GTFS"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2766ea3db82e90c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T12:58:22.825327Z",
     "start_time": "2025-07-04T12:58:06.796683Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== T√©l√©charge les donn√©es GTFS depuis https://api.oura3.cityway.fr/dataflow/offre-tc/download?provider=OURA&dataFormat=GTFS&dataProfil=OPENDATA ===\n",
      "Charg√© 24075 arr√™ts\n",
      "Charg√© 1456 lignes\n",
      "(Charg√© 1456 stop_times)\n",
      "(Charg√© 1456 trips)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_46882/386601745.py:25: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  stop_times_df = pd.read_csv(zip_file.open('stop_times.txt'))\n"
     ]
    }
   ],
   "source": [
    "stops_df, routes_df, stop_times_df, trips_df = download_gtfs_data(gtfs_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a7166f3d91ca37",
   "metadata": {},
   "source": "### Filtrer les arr√™ts"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "154ad85b7fc83d81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T13:07:16.008334Z",
     "start_time": "2025-07-04T13:07:15.693109Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Charge les contours des d√©partements fran√ßais depuis le fichier ../data/transportdatagouv/contour-des-departements.geojson ===\n",
      "=== Filtre spatialement les arr√™ts qui se trouvent dans les limites du d√©partement ===\n",
      "Nombre d'arr√™ts dans le 38: 7914 sur un total de 24075\n"
     ]
    }
   ],
   "source": [
    "filtered_stops = filter_stops_by_department(stops_df, department_code)\n",
    "print(\n",
    "    f\"Nombre d'arr√™ts dans le {department_code}: {len(filtered_stops)} sur un total de {len(stops_df)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632cfa0ac016780e",
   "metadata": {},
   "source": "### Filtrer les lignes"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f66995c16ec89d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T13:07:25.724643Z",
     "start_time": "2025-07-04T13:07:25.689505Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes dans le 38: 532 sur un total de 1456\n"
     ]
    }
   ],
   "source": [
    "filtered_routes = filter_routes_by_stops(routes_df, filtered_stops, trips_df, stop_times_df)\n",
    "print(\n",
    "    f\"Nombre de lignes dans le {department_code}: {len(filtered_routes)} sur un total de {len(routes_df)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ddc20a09afbd01",
   "metadata": {},
   "source": "## R√©sultats"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a83bf48d633bab8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T13:07:32.698606Z",
     "start_time": "2025-07-04T13:07:32.693299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Premiers arr√™ts filtr√©s:\n",
      "                     stop_id stop_code               stop_name   stop_lat  \\\n",
      "7209  FR:38001:ZE:3757:ISERE     16846            LA CHARRIERE  45.496367   \n",
      "7210  FR:38001:ZE:3758:ISERE     16847            LA CHARRIERE  45.496276   \n",
      "7211  FR:38001:ZE:3759:ISERE     16856             LES ETRAITS  45.502212   \n",
      "7212  FR:38001:ZE:3760:ISERE     16857             LES ETRAITS  45.502328   \n",
      "7213  FR:38001:ZE:3761:ISERE     16862              BEGENSIERE  45.500805   \n",
      "7214  FR:38001:ZE:3762:ISERE     16863              BEGENSIERE  45.501233   \n",
      "7215  FR:38001:ZE:4230:ISERE     17550                LA POSTE  45.537368   \n",
      "7216  FR:38001:ZE:4231:ISERE     17551                LA POSTE  45.537257   \n",
      "7217  FR:38001:ZE:4232:ISERE     17552  COLLEGE MARCEL BOUVIER  45.536197   \n",
      "7218  FR:38001:ZE:4233:ISERE     17553  COLLEGE MARCEL BOUVIER  45.536055   \n",
      "\n",
      "      stop_lon  \n",
      "7209  5.609307  \n",
      "7210  5.609524  \n",
      "7211  5.593296  \n",
      "7212  5.593205  \n",
      "7213  5.606018  \n",
      "7214  5.606007  \n",
      "7215  5.584515  \n",
      "7216  5.584268  \n",
      "7217  5.591411  \n",
      "7218  5.591252  \n"
     ]
    }
   ],
   "source": [
    "# Exemples d'arr√™ts\n",
    "print(\"\\nPremiers arr√™ts filtr√©s:\")\n",
    "print(filtered_stops[[\"stop_id\", \"stop_code\", \"stop_name\", \"stop_lat\", \"stop_lon\"]].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7168cbca49d6ce10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T12:59:41.822454Z",
     "start_time": "2025-07-04T12:59:41.814932Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Premi√®res lignes filtr√©es:\n",
      "                             route_id route_short_name  \\\n",
      "110          ARDECHE:Line:1000575:LOC              E04   \n",
      "134          ARDECHE:Line:1000601:LOC              E95   \n",
      "213       BOURGOINxJALLIEU:Line:1:LOC                1   \n",
      "214  BOURGOINxJALLIEU:Line:1021x2:LOC             1021   \n",
      "215  BOURGOINxJALLIEU:Line:1131x2:LOC             1131   \n",
      "216  BOURGOINxJALLIEU:Line:1141x2:LOC             1141   \n",
      "217  BOURGOINxJALLIEU:Line:1390x2:LOC             1390   \n",
      "218       BOURGOINxJALLIEU:Line:2:LOC                2   \n",
      "219  BOURGOINxJALLIEU:Line:2091x2:LOC             2091   \n",
      "220       BOURGOINxJALLIEU:Line:3:LOC                3   \n",
      "\n",
      "                     route_long_name  \n",
      "110  Annonay - St Rambert - le P√©age  \n",
      "134  Annonay - St Rambert - Le P√©age  \n",
      "213                                1  \n",
      "214                             1021  \n",
      "215                             1131  \n",
      "216                             1141  \n",
      "217                             1390  \n",
      "218                                2  \n",
      "219                             2091  \n",
      "220                                3  \n"
     ]
    }
   ],
   "source": [
    "# Exemples de lignes\n",
    "print(\"\\nPremi√®res lignes filtr√©es:\")\n",
    "print(filtered_routes[[\"route_id\", \"route_short_name\", \"route_long_name\"]].head(10))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
